% Template for PLoS
% Version 3.1 February 2015
%
% To compile to pdf, run:
% latex plos.template
% bibtex plos.template
% latex plos.template
% latex plos.template
% dvipdf plos.template
%
% % % % % % % % % % % % % % % % % % % % % %
%
% -- IMPORTANT NOTE
%
% This template contains comments intended 
% to minimize problems and delays during our production 
% process. Please follow the template instructions
% whenever possible.
%
% % % % % % % % % % % % % % % % % % % % % % % 
%
% Once your paper is accepted for publication, 
% PLEASE REMOVE ALL TRACKED CHANGES in this file and leave only
% the final text of your manuscript.
%
% There are no restrictions on package use within the LaTeX files except that 
% no packages listed in the template may be deleted.
%
% Please do not include colors or graphics in the text.
%
% Please do not create a heading level below \subsection. For 3rd level headings, use \paragraph{}.
%
% % % % % % % % % % % % % % % % % % % % % % %
%
% -- FIGURES AND TABLES
%
% Please include tables/figure captions directly after the paragraph where they are first cited in the text.
%
% DO NOT INCLUDE GRAPHICS IN YOUR MANUSCRIPT
% - Figures should be uploaded separately from your manuscript file. 
% - Figures generated using LaTeX should be extracted and removed from the PDF before submission. 
% - Figures containing multiple panels/subfigures must be combined into one image file before submission.
% For figure citations, please use "Fig." instead of "Figure".
% See http://www.plosone.org/static/figureGuidelines for PLOS figure guidelines.
%
% Tables should be cell-based and may not contain:
% - tabs/spacing/line breaks within cells to alter layout or alignment
% - vertically-merged cells (no tabular environments within tabular environments, do not use \multirow)
% - colors, shading, or graphic objects
% See http://www.plosone.org/static/figureGuidelines#tables for table guidelines.
%
% For tables that exceed the width of the text column, use the adjustwidth environment as illustrated in the example table in text below.
%
% % % % % % % % % % % % % % % % % % % % % % % %
%
% -- EQUATIONS, MATH SYMBOLS, SUBSCRIPTS, AND SUPERSCRIPTS
%
% IMPORTANT
% Below are a few tips to help format your equations and other special characters according to our specifications. For more tips to help reduce the possibility of formatting errors during conversion, please see our LaTeX guidelines at http://www.plosone.org/static/latexGuidelines
%
% Please be sure to include all portions of an equation in the math environment.
%
% Do not include text that is not math in the math environment. For example, CO2 will be CO\textsubscript{2}.
%
% Please add line breaks to long display equations when possible in order to fit size of the column. 
%
% For inline equations, please do not include punctuation (commas, etc) within the math environment unless this is part of the equation.
%
% % % % % % % % % % % % % % % % % % % % % % % % 
%
% Please contact latex@plos.org with any questions.
%
% % % % % % % % % % % % % % % % % % % % % % % %

\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in]{geometry}

% Use adjustwidth environment to exceed column width (see example table in text)
\usepackage{changepage}

% Use Unicode characters when possible
\usepackage[utf8]{inputenc}

% textcomp package and marvosym package for additional characters
\usepackage{textcomp,marvosym}

% fixltx2e package for \textsubscript
\usepackage{fixltx2e}

% amsmath and amssymb packages, useful for mathematical formulas and symbols
\usepackage{amsmath,amssymb}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

% Use nameref to cite supporting information files (see Supporting Information section for more info)
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% ligatures disabled
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% rotating package for sideways tables
\usepackage{rotating}

% Remove comment for double spacing
%\usepackage{setspace} 
%\doublespacing

% Text layout
\raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Bold the 'Figure #' in the caption and separate it from the title/caption with a period
% Captions will be left justified
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,justification=raggedright,singlelinecheck=off]{caption}

% Use the PLoS provided BiBTeX style
\bibliographystyle{plos2015}

%%%%%%%%%%%%%%%%%%%%%%% START - MY SETUP %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{url}\urlstyle{same}
\usepackage{booktabs}
\usepackage{colortbl, xcolor}
\usepackage{epstopdf}

% rysunki
\usepackage{tikz}
\usepackage{ifthen}
\usepackage{xxcolor}
\usetikzlibrary{arrows}
\usetikzlibrary[topaths]
\usetikzlibrary{decorations.pathreplacing}

%%%%%%%%%%%%%%%%%%%%%%% END - MY SETUP %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% Leave date blank
\date{}

% Header and Footer with logo
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
\lhead{\includegraphics[width=2.0in]{PLOS-submission.eps}}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}
\lfoot{\sf PLOS}

%% Include all macros below

\newcommand{\lorem}{{\bf LOREM}}
\newcommand{\ipsum}{{\bf IPSUM}}

%% END MACROS SECTION


\begin{document}
\vspace*{0.35in}

% Title must be 250 characters or less.
% Please capitalize all terms in the title except conjunctions, prepositions, and articles.
\begin{flushleft}
{\Large
\textbf\newline{Prediction of malarial signal peptides}
}
\newline
% Insert author names, affiliations and corresponding author email (do not include titles, positions, or degrees).
\\
Micha\l{}  Burdukiewicz\textsuperscript{1},
Piotr Sobczyk\textsuperscript{2},
Pawe\l{} B\l{}a\.{z}ej\textsuperscript{1},
Pawe\l{} Mackiewicz*\textsuperscript{1},
\\
\bigskip
\bf{1} University of Wroc\l{}aw, Department of Genomics, Poland
\\
\bf{2} Wroc\l{}aw University of Technology, Department of Mathematics, Poland
\\
\bigskip

% Use the asterisk to denote corresponding authorship and provide email address in note below.
* pamac@smorfland.uni.wroc.pl

\end{flushleft}
% Please keep the abstract below 300 words
\section*{Abstract}
Signal peptides play an essential role in targeting of proteins to endomembrane system and their export outside the cell. The proteins equipped with such peptides are of great importance in metabolism, maintenance of tissue structure, immune response and regulation of other organismal functions. These peptides may be recognized with adequate accuracy using learning systems. However, existing signal peptide predictors do not perform well on atypical signal peptides of the medically significant parasites belonging to the phylum Apicomplexa. That is why, we designed a new more universal probabilistic model for eukaryotic signal peptides, which includes knowledge about their organization, amino acid composition and variability. The proposed approach called signalHsmm is based on hidden semi-Markov models (HSMMs) and uses intrinsic knowledge about signal peptides. Since there are no experimentally confirmed signal peptides of \textit{Plasmodiidae}, our model extract universal decision rules from eukaryotic proteins with signal peptides. It is able to extracrecognize signal peptides from malaria parasites \textit{Plasmodium} and their relatives more accurately (with AUC = 0.93) than popular programs (0.89) while still being universal enough to provide prediction of eukaryotic signal peptides on par with the best preforming predictors. Moreover, it proved to be very stable regardless of types of learning data. Therefore, our model does not need to be permanently retrained with the continuous expansion of sequence databases. The web-server of signalHsmm is available at \url{http://smorfland.uni.wroc.pl/signalhsmm}.


% Please keep the Author Summary between 150 and 200 words
% Use first person. PLOS ONE authors please skip this step. 
% Author Summary not valid for PLOS ONE submissions.   
%\section*{Author Summary}


\linenumbers

\section*{Introduction}
\subsection*{Roles and features of signal peptides}

Proteins of eukaryotes are encoded in nuclear genomes and are synthesized in ribosomes located in the cytosol or bounded by the endoplasmic reticulum. After translation, proteins are targeted to specific subcellular compartments or exported outside the cell. The proper localization of proteins is essential to perform their desired function. Information about the protein destination is included within the very protein in short stretches of amino acid residues called targeting or sorting signals. One kind of them are signal peptides, which are located at the N-terminus of proteins.

Signal peptides are responsible for targeting of proteins via the Sec61 translocation channel~\cite{2007rapoportprotein} to endomembrane system, which includes endoplasmic reticulum and Golgi apparatus. Such proteins can stay inside these compartments, can be inserted into cellular membranes or exported outside the cell. Proteins equipped with signal peptides play crucial role in metabolism ($\beta$ galactosidase, pepsins)~\cite{1991hofmannmutations}, maintenance of tissue structure (collagen)~\cite{2001chanaberrant}, immune response (interferons, interleukins)~\cite{2005zhangalteration} and regulation of other organismal functions (prolactin, glucagon)~\cite{2010huangrole}. Moreover, passing proteins through the endomembrane system is important for their correct folding and posttranslational modification such as glycosylation and phosphorylation.

The important functions of signal pepties makes them potential drug targets. It is especially true for malarial signal peptides, whose additionally mark proteins directed to the apicoplast, a unique organellum specific only for \textit{Apicomplexa}~\cite{2003foththe}. Anti-malarial drugs targeting apicoplast pathways should be safe for the host~\cite{1997ficheraa, 2003gornickiapicoplast, 2010garciaestradadna}. Other potential apicomplexan drug target, the food vacuole, also imports proteins tagged with the signal peptide~\cite{2002egandiscovering}. The model of malarial signal peptide would aid in the computational design of drugs. Unfortunaly, there are no experimentally confirmed signal peptides for this taxon which hinders creation of such model.

Nevertheless, some data indicate that signal peptides may be universal. It was found, for example, that even bacterial signal peptides targeted correctly transgenic proteins to plant~\cite{2009moellera} or mammalian secretory systems~\cite{2014naganoestablishment}. The signal peptides of other \textit{Eukaryota} may reveal features typical also for signal peptides employed by organisms belonging to \textit{Plasmodiidae} family.

Despite the low sequence homology between signal peptides~\cite{1999ladungaphysean}, some general architecture were proposed~\cite{1994izardsignal, 2013vossmechanism} - Fig. \ref{fig:sparch}. It is assumed that signal peptides start with a positively charged sequence of amino acid residues, called the n-region with the length of about 5-8 residues. They probably enforce a proper topology on the polypeptide during its translocation through membrane based on the positive-inside rule~\cite{1988vonheijnetopogenic}. The first region is followed by a stretch of hydrophobic amino acids (h-region) with the length of about 8-12 residues. It constitutes a core region of signal peptide and usually forms $\alpha$-helix. The third part of a signal peptide is a polar, but uncharged c-region. It is usually 6 residues long and ends with a cleavage site, in which a signal peptidase cleaves the signal peptide, during or after translocation of the protein into the endoplasmic reticulum ~\cite{2002paetzelsignal}. The cleavage site is characterized by a variable amino acid composition. It typically contains small and neutral residues at -3 and -1 positions~\cite{1994palzkillselection}. This site is, however, absent from some membrane proteins in which the first transmembrane domain acts both as a signal peptide and signal anchor~\cite{1988szczesnaskorupapositive}. The amino acid composition and the length of these regions vary between signal peptides, which influences the efficiency of protein secretion~\cite{2006hegdethe}.

On the other hand, signal peptides show great variation and the description presented above (Fig. \ref{fig:sparch}) refers to the most "typical" signal peptides. There are  exceptionally long signal peptides, which fulfill more sophisticated roles~\cite{2009hissarchitecture}. The fragment of signal peptide from preprolactin takes part in the regulation of prolactin secretion, whereas signal peptides of MHC class I inhibit activity of NK cells. Signal peptides of viral origin are involved in the immune evasion or viral life cycle~\cite{2000kappposttargeting}. The signal peptide from midkine contributing to the tumor progression contains epitopes recognized by CD4+ T cells~\cite{2013kerzerhothe}. The functional significance of these targeting signals makes that the prediction of signal peptide-containing proteins is also an important step in the drug development~\cite{2005zhangalteration, 2012netoadeimproving, 2010moellerwetmilling}.


\begin{figure}[ht]\centering
\includegraphics[width=0.55\textwidth]{figures/SP.eps}
\caption{The organization of typical signal peptide. The regions are not drawn in scale.}
\label{fig:sparch}
\end{figure}

The design of more general signal peptide model, suitable also for \textit{Plasmodiidae}, requires some simplifications. The recent advancements in the proteomics suggest that a simplification of amino acid alphabet (by reducing the number of letters) may lead to better fold recognition~\cite{2000murphysimplified, 2009petersonreduced}. Considering that one of the key features of signal peptide is its secondary structure ($\alpha$-helix), the universal model may utilize shorter amino acid alphabet, where several similar amino acids are unified into a single group.

\subsection*{Signal peptides predicting software}

Although many experimental methods determining the subcellular localization of proteins were devised, they are time consuming and laborious. Therefore, signal peptides became the subject of many computational programs to their prediction. Many software incorporates 'black-box’ models, such as: neural networks~\cite{2011petersensignalp}, support vector machines~\cite{2014zhangprediction}, Bayesian networks~\cite{2012zhengsignalbnf} or k-nearest neighbours~\cite{2007shensignall}. However, these models do not provide direct biological information about organization of signal peptides and are not able to predict properly atypical signal peptides. Although there are programs that do not share the innate flaws of 'black-box' models, they also demand an improvement. Some of them are based on position matrices or their variants~\cite{2014zhangprediction, 2004hillerpredisi}. Others (Phobius, Philius and SignalP 3.0) use hidden Markov models (HMMs)~\cite{2004klla, 2008reynoldstransmembrane, 2004bendtsenimproved}, which try to reflect structure of signal peptides regions in their limited probabilistic frameworks. The used HMMs, however, imply a geometric distribution for duration of regions length. We studied the distribution for regions from the first work utilizing HMMs in prediction of signal peptides~\cite{1998nielsenprediction} and found that the length distribution for every region was not geometric (Fig. \ref{fig:reglen}). Moreover, the commonly used rigid scheme of signal peptide's organization (Fig. \ref{fig:sparch}) does not describe extremely long or short peptides. Theoretically, HMMs that describe the atypical signal peptides could be developed to consider also the unusual structures but such probabilistic frameworks have not yet been implemented.

\begin{figure}[ht]\centering
\includegraphics[width=0.95\textwidth]{figures/reglen.eps}
\caption{Distribution of lengths of signal peptides (A) and their regions (B) expressed in the number of amino acid residues. The data was extracted from 2~589 signal peptide sequences derived from UniProt database (see \textbf{Data selection} in \textbf{Methods}). Yellow bars represent density of geometric distribution, where $\mu = \frac{1}{p}$.}
\label{fig:reglen}
\end{figure}

% All programs used in signal peptide recognition are trained on real protein sequences. Therefore, they succeed in the recognition of peptides similar to those in the learning set but fail in the case of artificial signal peptides. Such peptides are designed to increase effectiveness of protein secretion~\cite{2010futatsumorisugaisignal}. They are especially important in industrial applications to increase yield of proteins. Therefore, only explicit knowledge about the organization of signal peptides allows creating sequences that will be the most efficient in the export of proteins~\cite{2013ngengineering}. Signal peptides have also an important application in gene therapy. Mimicking the natural mechanism of protein export, artificial signal peptides with tumor epitopes increase the antitumor immune response~\cite{2003heenhanced}. Such epitopes must be properly inserted into a signal peptide without decreasing its secretion properties through disruption of the regional structure. Instead of time-consuming and expensive laboratory experiments, it would be very useful to survey \textit{in silico} many artificial peptides to select the ones that would fulfill the designed role.

Majority of the signal peptide predicting software uses the orthogonal encoding of amino acids, in which a vector of 20 digits represents every amino acid. This method of encoding, however, does not take into account relationships between amino acids and differences in their physicochemical properties. This is disadvantage of such signal peptide models because their regions are in fact characterized by specific features of amino acid residues and not by the simple occurrence of specific amino acids. In addition to this, such sparse encoding enforces larger data sets, which hinders their management and analysis~\cite{2002linamino}. Therefore, we elaborated a new approach based on hidden semi-Markov models using grouping of amino acids into physicochemical groups characteristic of signal peptides. %The new methods proved better in comparison to the current software.

\section*{Methods}

\subsection*{Overview}

Since the functionality of signal peptides depends on the physicochemical properties of residues in a given region, we clustered amino acids into several groups based on their characteristics. The pre-processed sequences were further analyzed by the heuristic algorithm, which determines borders between three characteristic signal peptide regions~\cite{1998nielsenprediction}. We refined some region recognition criteria to attune the algorithm to less typical signal peptides. Next, two models were trained to recognize proteins with and without a signal peptide. The first one was a hidden semi-Markov model, in which each of three signal peptide regions was represented by a different hidden state. The additional fourth hidden state represented a mature protein. Each state was described by its frequencies of amino acid groups. The distribution of hidden states durations, i.e. the number of amino acids, was based on the empirical distribution of region lengths from the training set. Furthermore, the hidden semi-Markov model was enriched with n-grams representing signal peptide cleavage sites. The second model was a simple probabilistic approach in which no association between amino acids was assumed and probability of amino acids groups occurrence was determined by their frequencies in mature proteins.

\subsection*{Data selection}

Since there are no experimentally confirmed signal peptides of proteins belonging \textit{Plasmodiidae}, we decided to train the predictor using signal peptides of other Eukaryotes. Eukaryotic protein sequences and their annotations were downloaded from UniProt database release 2015\_06. The preparations included the usual removal of sequences with more than one cleavage site, unknown cleavage site position, ambiguous symbols: X, J, Z, B or selenocysteine (U) from the final data set. We also created a testing data set consisting of proteins belonging to the organisms from \testit{Plasmodiidae} family. The positive set contained 102 sequences with a putative signal peptide, containing its start and cleavage site information. The negative set comprised 358 sequences without any signal peptide annotation.

\subsection*{Homology reduction}

To reduce homology of obtained protein sequences, we filtered them using cd-hit~\cite{2012fucdhit}. For sequences with signal peptide, we use only signal peptides for homology reduction. For protein without signal peptide, we used first 70 amino acids as proposed elsewhere~\cite{1997nielsenidentification}.

We prepare two learning data sets by removing homology on 90\% threshold (word length 5) and 50\% (word length 2). The testing data set was filtered only on 50\% threshold with words of lenth 2.

\subsection*{Clustering of amino acids}

signalHsmm is not the first software which uses reduced amino acid alphabet in signal peptide prediction. BLOMAP~\cite{maetschke2005blomap} also employed the similar strategy but considered only substitution matrices. However, we applied different approach. We clustered amino acids using four properties relevant for the architecture of signal peptide: their hydrophobicity, frequency in $\alpha$-helices, polarity and size. The high hydrophobicity is a determinant of the h-region, whose $\alpha$-helix secondary structure is probably induced by the positively charged n-region. The high polarity as well as small size are important features of residues in the cleavage site~\cite{1994palzkillselection}.

\begin{table}[ht]
\centering
\caption{Properties used in amino acid clusterization.} 
\begin{tabular}{ll}
  \toprule
Property name & Amino acid scale \\ 
  \midrule
Size & Size~\cite{dawson1972size} \\ 
   \rowcolor[gray]{0.85}Size & Molecular weight~\cite{fasman1976handbook}\\ 
  Size & Residue volume~\cite{1973goldsackcontribution} \\ 
   \rowcolor[gray]{0.85}Size & Bulkiness~\cite{1968zimmermanthe} \\ 
  Hydrophobicity & Normalized hydrophobicity scales for $\alpha$-proteins~\cite{1992cidhydrophobicity} \\ 
   \rowcolor[gray]{0.85}Hydrophobicity & Consensus normalized hydrophobicity scale~\cite{1984eisenbergthreedimensional} \\ 
  Hydrophobicity & Hydropathy index~\cite{1982kytea} \\ 
   \rowcolor[gray]{0.85}Hydrophobicity & Surrounding hydrophobicity in $\alpha$-helix~\cite{1980ponnuswamyhydrophobic} \\ 
  Polarity & Polarity~\cite{1974granthamamino} \\ 
   \rowcolor[gray]{0.85}Polarity & Mean polarity~\cite{1988radzickainfluences} \\ 
  Frequency in $\alpha$-helices & Signal sequence helical potential~\cite{1982argosstructural} \\ 
   \rowcolor[gray]{0.85}Frequency in $\alpha$-helices & Normalized frequency of N-terminal helix~\cite{chou1978prediction} \\ 
  Frequency in $\alpha$-helices & Relative frequency in $\alpha$-helix~\cite{1990prabhakaranthe} \\ 
   \bottomrule
\end{tabular}
\label{tab:aaprop}
\end{table}

We considered in total 13 amino acid scales from AAIndex database~\cite{2008kawashimaaaindex} (Tab.~\ref{tab:aaprop}). We selected one scale per property and carried out all possible 96 permutations of them. Based on that, we created 96 possible clusterings of amino acids using Euclidean distance and Ward's method. Next, we cut the clusterings to create four group of amino acids. In 31\% of cases, the groupings were identical. To compare the usefulness of encodings, we performed a 5-fold cross-validation training the new instance of signalHsmm on every encoding. We created balanced data sets by subsampling proteins without a signal peptide to equal the number of proteins with a signal peptide. The cross-validation was repeated 60 times to ensure that every protein without signal peptide was included in the learning set with the probability higher than 0.5. Very small variance of performance measures (for example see Tab.~\ref{tab:perfmeas}) confirmed the credibility of cross-validation.

\subsection*{Hidden semi-Markov model}
Hidden semi-Markov model (HSMM) is an extension of hidden Markov model (HMM). 
Let us first briefly describe the idea of the HMM. 
Suppose we have a sequence of observations, e.g. amino acids, and we are interested in understanding an underlying cause of their occurrence. 
HMM aims to answer that question assuming a specific and yet flexible structure of the problem.
HMM consists of two stochastic processes. The first is a discrete Markov chain $X_{t=1}^T$ on the set of so called hidden states $\{S_1, \dots S_n\}$.
They are "the cause" of the observations. At every step $t$, hidden state might change according to a transition matrix
$A= (a)_{i,j=1}^n$, where $a_{i,j} = \mathcal{P}(X_{t+1} = S_j | X_t = S_i)$. In our application, hidden states are signal peptide regions.
The second process $E_{t=1}^T$ is an observation process defined on the set of possible observations $\{O_1, \dots, O_m\}$. They are assumed to occur independently and conditionally on the hidden state that emits it. 
Their distribution are given by a matrix $B$, $b_{i,k} = \mathcal{P}(E_t = O_k | X_t = S_i)$.
In our case, the observations are (encoded) amino acids.
The main goal in signalHsmm is to find the most probable regions boundaries for a given peptide. This is achieved with Viterbi algorithm.
For a good reference on HMM see~\cite{1989rabinera}.

In the regular HMM, the hidden state duration, i.e. the number of observations emitted by the hidden state, has a geometric distribution. \cite{Durbin98biologicalsequence} showed how to extend it for different distributions without significant increase in computational 
complexity. Similar ideas were used for signal peptide recognition, for example by~\cite{2004klla}. 
However, it is still not flexible enough because the empirical regional length distributions (see Fig.~\ref{fig:reglen})
are difficult to capture in this way.

%rysunek pokazujący o co chodzi w HMM
\begin{figure}[h]
\centering
\tikzstyle{block} = [draw,shape=circle, top color=green!50!white!70, bottom color=green!50!white!70 ,minimum size=4em]
\tikzstyle{blockComp} = [draw,shape=circle, top color=red!50!white!70, bottom color=red!50!white!70 ,minimum size=2.5em]
% diameter of semicircle used to indicate that two lines are not connected
\def\radius{.7mm} 
\tikzstyle{branch}=[shape=rectangle, top color=white, bottom color=white ,minimum size=3pt,inner sep=0pt]
\tikzstyle{branch2}=[shape=rectangle, top color=white, bottom color=white ,minimum size=3pt,inner sep=0pt]
\def\n{11}
 \tikzstyle{line} = [draw=black, color=black!70!white!50, line width=1.5mm, -latex'] 
 \tikzstyle{line2} = [draw=black, color=red!30!white!70, line width=1.5mm, -latex']
\tikzstyle{frame}=[text=black,above, bottom color=white, top color=blue!50!black!70  ]
\tikzstyle{frameComp}=[text=black,below, bottom color=red!50!white!70, top color=red!50!white!70  ]
 \tikzstyle{line3} = [color=green!50!black!70, line width=1.5mm]
\def\names{{"$O_{1,1}$","...","$O_{1,d_1}$", "...","$O_{k, 1}$", "...", "$O_{k, d_k}$"}}%
\begin{tikzpicture}[>=latex']
%wąsate nawiasy
\draw [decorate, decoration={brace,amplitude=10pt},line3,xshift=0pt,yshift=0pt] (2.5,1) -> (10.5,1) node [branch,midway,yshift=0.8cm,color=black] 
	{\textbf{Hidden states}};
% \draw [->,decoration={brace,mirror,amplitude=10pt},line2,xshift=0pt,yshift=0pt] (11,-3) -- (3,-3) node [branch2,midway,yshift=-0.6cm,color=black] 
% 	{\textbf{Kierunek odczytu na nici Cricka ($3' \to 5'$)}}; 
   % Draw blocks, inputs and outputs
 
\node[block, text width=3em] at (1+2,0) (block1) {\footnotesize 1st hidden state};
\node[blockComp] at (-.5+2,-2)  (komp1) {\footnotesize \pgfmathparse{\names[0]}\pgfmathresult};
\node[blockComp] at (1+2,-2)  (komp2) {\footnotesize \pgfmathparse{\names[1]}\pgfmathresult};
\node[blockComp] at (2.5+2,-2)  (komp3) {\footnotesize \pgfmathparse{\names[2]}\pgfmathresult};
\draw[line,->]  (block1) --  (komp1);
\draw[line,->]  (block1) --  (komp2);
\draw[line,->]  (block1) --  (komp3);
\draw[line3,->] (block1.east) -- +(2,0) node [branch,midway,yshift=0.3cm,xshift=-0.2cm,color=black] {\footnotesize \textbf{transition}};

\node[block, bottom color=green!50!white!80,] at (4.5+2,0) (block2) {...};
\draw[line3,->] (block2.east) -- +(2,0) node [branch,midway,yshift=0.3cm,xshift=-0.2cm,color=black] {\footnotesize \textbf{transition}};
\node[blockComp] at (4.5+2,-2)  (komp4) {\footnotesize \pgfmathparse{\names[3]}\pgfmathresult};
\draw[line,->]  (block2) --  (komp4) ;

\node[block,text width=3em, bottom color=green!50!white!70] at (8+2,0) (block3) {\footnotesize $k^{th}$ hidden state};
\node[blockComp] at (6.5+2,-2)  (komp5) {\footnotesize \pgfmathparse{\names[4]}\pgfmathresult};
\node[blockComp] at (8+2,-2)  (komp6) {\footnotesize \pgfmathparse{\names[5]}\pgfmathresult};
\node[blockComp] at (9.5+2,-2)  (komp7) {\footnotesize \pgfmathparse{\names[6]}\pgfmathresult};
\draw[line,->]  (block3) --  (komp5);
\draw[line,->]  (block3) --  (komp6);
\draw[line,->]  (block3) --  (komp7);

% \draw[<->, color=red!30!black!50, line width=1.5mm] (komp1) |- +(5,-1.5) node[line2, yshift=-0.5cm] {\textbf{Observations}} -| (komp7); 

\draw [color=red!50!black!70, line width=1.5mm, decorate,decoration={brace,amplitude=10pt,mirror,raise=10pt},yshift=-10pt]
(1,-1.8) -- (5,-1.8) node [branch2, midway, yshift=-1cm,color=black] {\textbf{Duration of length $d_1$}};

\draw [color=red!50!black!70, line width=1.5mm, decorate,decoration={brace,amplitude=10pt,mirror,raise=10pt},yshift=-10pt]
(8,-1.8) -- (12,-1.8) node [branch2, midway, yshift=-1cm,color=black] {\textbf{Duration of length $d_k$}};

\draw [color=red!50!black!70, line width=1.5mm, decorate,decoration={brace,amplitude=15pt,mirror,raise=10pt},yshift=-10pt]
(1,-2.6) -- (12,-2.6) node [branch2, midway, yshift=-1.3cm,color=black] {\textbf{Observations, $\sum_{i=1}^k d_i = T$}};
\end{tikzpicture}
\caption{General scheme of hidden semi-Markov model.}
\label{fig:hsmm}
\end{figure}


The model we used is Hidden semi-Markov Model (HSMM)~\cite{Yu2010215}. It extends HMM by allowing any given hidden state duration distribution (Fig.~\ref{fig:hsmm}).
In addition to matrices $A$ and $B$, the model is given by probabilities of duration length in hidden states.
$$\mathcal{P}(\text{duration in state} = d | \text{state is } S_i), \;\; i = 1, \dots, n, \;\; d = 1, \dots, D$$
where $D$ is the maximum allowed duration.
As our datasets are of reasonable size and $D$ is small -- around 30, computational effort is not much 
higher than in the regular HMM. 

Our model has a very specific structure. The hidden states represent signal peptide regions.
Almost all entries in the transition matrix $A$ are zeros because regions are sequential.
Possible transitions are depicted as arrows in Fig.~\ref{fig:ngramext}.
Probabilities of observations for the hidden states and hidden states durations were estimated from training data.
The advantage of HSMM model is not only a better performance but also its straightforwardness.
Fig.~\ref{fig:ngramext} is easy to interpret for a researcher without any mathematical background.

%model structure

\begin{figure}[ht]\centering
\includegraphics[width=0.51\textwidth]{figures/HSMMs.eps}
\caption{The diagram of simple (A) and extended version of signalHsmm with the n-gram cleavage site model (B).}
\label{fig:ngramext}
\end{figure}

    
\subsection*{Extension of n-grams}

Hidden semi-Markov models may be flexibly enhanced by adding additional hidden states. To improve our model, we added few supplementary states representing specific motives that might occur in the proximity of cleavage site. The structure of cleavage sites, more conserved than other parts of signal peptide~\cite{2004hillerpredisi}, may be reflected by n-grams (k-mers), short vectors of $n$ characters derived from input sequences. Using the biogram software~\cite{biogramPackage}, we extracted n-grams from cleavage sites of signal peptides. The analyzed sequences were already encoded using amino acid classification providing the best sensitivity of the general model (Tab. \ref{tab:best}). Selected n-grams representing less common cleavage site motifs were included in the HSMM model as alternative paths at the end of c-region (Fig.~\ref{fig:ngramext}B).


\section*{Results and discussion}

\subsection*{Cross-validation}

\begin{figure}[ht]\centering
\includegraphics[width=0.95\textwidth, height=7cm]{figures/cvres.eps}
\caption{Sensitivity and specificity of amino acid encodings after cross-validation. 1 indicates the encoding providing the best sensitivity ($\textrm{AUC} = 0.9683$, $\textrm{MCC} = 0.8677$), whereas 2 means the encoding providing the best specificity ($\textrm{AUC} = 0.9338$, $\textrm{MCC} = 0.6474$).}
\label{fig:cvres}
\end{figure}

\begin{table}[ht]
\begin{minipage}{.5\linewidth} 
\centering
\caption{The best sensitivity (final) encoding.} 
\begin{tabular}{l}
  \toprule
Groups \\ 
  \midrule
D, E, H, K, N, Q, R \\ 
   \rowcolor[gray]{0.85}G, P, S, T, Y \\ 
  F, I, L, M, V, W \\ 
   \rowcolor[gray]{0.85}A, C \\ 
   \bottomrule
\end{tabular}
\label{tab:best}
\end{minipage}
\begin{minipage}{.5\linewidth} 
\centering
\caption{The best specificity encoding.} 
\begin{tabular}{l}
  \toprule
Groups \\ 
  \midrule
A, E, K, Q, R \\ 
   \rowcolor[gray]{0.85}D, G, N, P, S, T \\ 
  C, H, I, L, M, V \\ 
   \rowcolor[gray]{0.85}F, W, Y \\ 
   \bottomrule
\end{tabular}
\label{tab:worst}
\end{minipage}
\end{table}


\begin{figure}[ht]\centering
\includegraphics[width=0.95\textwidth]{figures/enccomp.eps}
\caption{Comparison of amino acid encodings with the best sensitivity and the best
specificity in different regions of signal peptide and mature proteins according to: A) the normalized value of properties for particular amino acids (points) and B) frequencies of amino acids in the given region.}
\label{fig:enccomp}
\end{figure}

We used four performance measures to evaluate results of cross-validation: specificity, sensitivity, Matthew's Correlation Coefficient ($\phi$ coefficient) and Area Under the Curve (AUC). All encodings provided very good AUC (0.93 -- 0.97) and specificity (0.92 -- 0.96). The classification of amino acids had the biggest impact on sensitivity, which ranges from 0.66 to 0.94. The final signalHsmm algorithm uses the encoding that yields the highest specificity and Matthew's Correlation coefficient as well as the second best AUC (Fig.~\ref{fig:cvres}).

\begin{table}[ht]
\centering
\caption{Performance measures for the best encoding. 60 repetitions of cross-validation.} 
\label{tab:perfmeas}
\begin{tabular}{lrr}
  \toprule
Measure & Mean & SD \\ 
  \midrule
AUC & 0.9682 & 0.0023 \\ 
   \rowcolor[gray]{0.85}Sensitivity & 0.9407 & 0.0008 \\ 
  Specificity & 0.9272 & 0.0050 \\ 
   \rowcolor[gray]{0.85}MCC & 0.8681 & 0.0049 \\ 
   \bottomrule
\end{tabular}
\end{table}

\subsection*{Comparison of encodings}

We examined in detail encodings with the best sensitivity and the best specificity (Tab.~\ref{tab:best}, Tab.~\ref{tab:worst} and Fig.~\ref{fig:enccomp}). In both cases, the group 1 tends to contain average-sized polar amino acids. In the best sensitivity encoding, all charged amino acids, both acidic and basic (also weakly basic histidine) belong to this group. These amino acids are nearly absent from h-region and provide very good distinction between regions of signal peptide (Fig.~\ref{fig:enccomp}). In the best specificity encoding, where polar and charged character of the group 1 is not so explicit, the difference in its distribution between the regions is also less visible.
The amino acids belonging to the group 2 have a quite low probability of occurrence in $\alpha$-helix and are very diverse. This group includes polar but uncharged serine and threonine as well as hydrophobic tyrosine, aliphatic glycine and proline. In the best specificity encoding, the polar character of this group is emphasized by the addition of asparagine and aspartic acid. Despite these differences, the distribution of group 2 seems to be comparable in two encodings. The both groupings have strongly non-polar and aliphatic group 3 containing isoleucine, leucine, methionine and valine. The hydrophobic property of this group in the best sensitivity encoding are even more pronounced by the presence of tryptophan and phenylalanine. On the contrary, more polar histidine belongs to the group 3 in the best specificity encoding. Because of the hydrophobic character, this group dominates in the h-region in the case of both amino acid classifications.
The fourth group is the most diverse in both encodings. In the case of the best specificity encoding, this group comprises aromatic amino acids: phenylalanine, tryptophan and tyrosine. In contrast, the group 4 in the best sensitivity encoding contains only alanine and cysteine, which both are rather small amino acids and tend to appear in $\alpha$-helices. This very unique composition seems to be typical of the c-region of signal peptide.

The encoding of amino acid plays crucial role in the recognition of signal peptide but does not affect identification of proteins without signal peptides (compare change in specificity and sensitivity on Fig.~\ref{fig:cvres}). The mature protein state in the HSMM model tends to have a more uniform distribution of residues than signal peptide region, which makes it more resistant to changes in amino acid groupings.

\subsection*{Benchmark tests}

To provide the honest comparison, we trained our model on 2311 signal peptide-containing sequences deposited in Uniprot until 2010 year (an iteration of signalHsmm called signalHsmm-2010). The data set should correspond to the set used to train SignalP 4.1, the newest classifier present in the benchmark. In addition to this, we prepared smaller data set, covering only 336 sequences collected till 1987 year, just after the first method predicting signal peptide was published~\cite{1986vonheijnea}. The signalHsmm-1987 iteration has to extract the signal peptide model from data set much limited than training sets of any classifier included in the benchmark. 

The testing data set extracted from UniProt data base contained 102 sequences with a signal peptide and 358 sequences without it belonging to organisms from \textit{Plasmodiidae} family (respectively 51 and 211 after homology reduction).

Together with signalHsmm, we evaluated several signal peptide predicting algorithms: signalP 4.1, PrediSi, Phobius and Philius (See Tab.~\ref{tab:bench2010plas} for the most common performance measures, and Supplemental Table~\ref{tab:bench2010plas_full} for all performance measures). The older version of signalP 4.1, signalP 3.0, was also incorporated in the analysis, because it is often chosen over its newer counterpart in the analysis of sequences belonging to Apicomplexa~\cite{2012cilingirapicoap}.

We trained several versions of signalHsmm  based on iteration described above to separately check improvements introduced by our software: a new probabilistic model (hidden semi-Markov models) and a simplified alphabet of amino acids. The latter was addressed by training signalHsmm on raw amino acids sequences (denoted 'raw aa' in the table). The performance of this iteration was slightly lower than performance of its counterpart trained on the reduced alphabet. This result confirms that unique function of signal peptide does not depend on specific amino acids, but on more general features and our simpler model is able to portrait the unique architecture of signal peptide more accurately.

The advantage of hidden semi-Markov model over normal Markov model can be seen through the comparison of the signalHsmm with signal peptide predictors utilizing HMM: Phobius, Philius and signalP 3.0 (HMM).

To check susceptibility of our model to overfitting, we trained several iterations on data sets with different levels of homology reduction. We discovered that our model, probably thanks to its relative simplicity, does not overfit and results are similar for models with very restrictive and no homology reduction.

\begin{table}[ht]
\centering
\caption{Comparison of Area Under the Curve, H-measure and Matthews Correlation Coefficient 
for different classifiers considering proteins belonging to \textit{Plasmodiidae}.} 
\label{tab:bench2010plas}
\begin{tabular}{rllll}
  \toprule
 & AUC & Sensitivity & Specificity & MCC \\ 
  \midrule
signalP 4.1 (no tm) \cite{2011petersensignalp} & 0.8816 & 0.8627 & 0.9005 & 0.6997 \\ 
   \rowcolor[gray]{0.85}signalP 4.1 (tm) \cite{2011petersensignalp} & 0.7927 & 0.6471 & 0.9384 & 0.6093 \\ 
  signalP 3.0 (NN) \cite{2004bendtsenimproved} & 0.8938 & 0.8824 & 0.9052 & \textbf{0.7220} \\ 
   \rowcolor[gray]{0.85}signalP 3.0 (HMM) \cite{2004bendtsenimproved} & 0.7773 & \textbf{1.0000} & 0.5545 & 0.4416 \\ 
  PrediSi \cite{2004hillerpredisi} & 0.6453 & 0.3333 & \textbf{0.9573} & 0.3849 \\ 
   \rowcolor[gray]{0.85}Phobius \cite{2004klla} & 0.7707 & 0.6078 & 0.9336 & 0.5684 \\ 
  Philius \cite{2008reynoldstransmembrane} & 0.7880 & 0.6471 & 0.9289 & 0.5895 \\ 
   \rowcolor[gray]{0.85}signalHsmm-2010 & \textbf{0.9372} & \textbf{1.0000} & 0.7583 & 0.6157 \\ 
  signalHsmm-2010 (raw aa) & 0.9216 & 0.9608 & 0.7109 & 0.5389 \\ 
   \rowcolor[gray]{0.85}signalHsmm2010 (hom. 90\%) & 0.9371 & \textbf{1.0000} & 0.7251 & 0.5825 \\ 
  signalHsmm2010 (hom. 50\%) & 0.9354 & \textbf{1.0000} & 0.7536 & 0.6108 \\ 
   \rowcolor[gray]{0.85}signalHsmm-1987 & 0.9356 & 0.9608 & 0.8057 & 0.6391 \\ 
  signalHsmm-1987 (raw aa) & 0.9215 & 0.9608 & 0.8152 & 0.6505 \\ 
   \rowcolor[gray]{0.85}signalHsmm1987 (hom. 90\%) & 0.9358 & 0.9804 & 0.7962 & 0.6426 \\ 
  signalHsmm1987 (hom. 50\%) & 0.9357 & 0.9608 & 0.8057 & 0.6391 \\ 
   \bottomrule
\end{tabular}
\end{table}

The overall simplicity of our approach does not hinder its capabilities of recognising signal peptides from other taxa. We also benchmarked signalHsmm iterations and other software on the set of 127 Eukaryotic proteins with signal peptide added after year 2010 to UniProt and randomly chosen 127 proteins without signal peptide (homology in the testing set was reduced as described above). signalHsmm-2010 performed comparably to signalP 4.1 (both achieved AUC above 0.97, see Supplemental Table~\ref{tab:bench2010_full} for all performance measures).

\subsection*{Conclusions}

We propose a novel solution to the problem of predicting signal peptides in proteins of \textit{Plasmodiidae} using only data coming from the signal peptides coming from other Eukaryotes. Our software is not limited to very specific taxonomic group, but is able to compete with state-of-art algorithms in predicting signal peptides of other organisms.

One of the most important features of signalHsmm is its stability. The difference in performance measures of iterations trained on large and small data set is marginal. It implies that signalHsmm extracts roughly the same general architecture of signal peptide regadless of the size of training data set. Moreover, the decision rules are roughly comparable for iterations trained on data sets without removal of homologues sequences.  Such result may suggest, that our probabilistic model is at least partially resistant to overfitting and do not adjust itself to the patterns most common in training data sets. On the contrary, signalHsmm always retrieves the universal model of signal peptide.

The existing signal peptide detecting software usually does not reveal decision rules responsible for predictions. Considering the biological context of the problem, we see a need for a transparent model of signal peptide. signalHsmm is the first step in this direction. The encoding of amino acids not only reduces dimensionality of the problem, but also makes our probabilistic model more interpretable. We were able to determine that properties of signal peptides do not depend on their exact sequence but on the physicochemical features of the amino acids. The model confirmed not only the high hydrophibicity of the h-region and polarity of the n-region but also found that alanine is one of the most typical amino acids in the c-region.

The flexibility and efficient information recovery makes our model unique among similar software. signalHsmm models properly very specific signal peptides belonging to taxonomic groups which are poorly represented in databases. Moreover, our method can effectively extract information from very small data sets, which in future may lead to new predictors specialized in recognition of atypical signaling sequences.


\subsection*{Availability and implementation}
The signalHsmm prediction web-server is available at: \url{http://smorfland.uni.wroc.pl/signalhsmm}. signalHsmm is implemented as an R package available at: \url{http://cran.r-project.org/web/packages/signalHsmm}. Stand-alone version offers prediction and tools to build, train and test novel signal peptide models.

\section*{Supporting Information}

\subsection*{S1 Table}
\label{tab:bench2010plas_full}
{\bf Benchmark results - \textit{Plasmodiidae}.} Performance measures for benchmark test of signal peptide predictors using sequences belonging to \textit{Plasmodiidae}.

\subsection*{S2 Table}
\label{tab:bench2010_full}
{\bf Benchmark results - Eukaryots} Performance measures for benchmark test of signal peptide predictors using eukaryotic sequences.

\section*{Acknowledgments}

\section*{Author Contributions}
MB and PM designed the study. All authors participated in the design of the study. PB and PS created the probabilistic model. MB and PS implemented the model and wrote the software. MB and PM drafted the manuscript. All authors critically revised the manuscript.

\nolinenumbers

\section*{References}

\bibliography{lokalizom}


% Either type in your references using
% \begin{thebibliography}{}
% \bibitem{}
% Text
% \end{thebibliography}
%
% OR
%
% Compile your BiBTeX database using our plos2015.bst
% style file and paste the contents of your .bbl file
% here.
% 
% \begin{thebibliography}{10}
% \bibitem{bib1}
% Devaraju P, Gulati R, Antony PT, Mithun CB, Negi VS. Susceptibility to SLE in South Indian Tamils may be influenced by genetic selection pressure on TLR2 and TLR9 genes. Mol Immunol. 2014 Nov 22. pii: S0161-5890(14)00313-7. doi: 10.1016/j.molimm.2014.11.005
% 
% \bibitem{bib2}
% Huynen MMTE, Martens P, Hilderlink HBM. The health impacts of globalisation: a conceptual framework. Global Health. 2005;1: 14. Available: http://www.globalizationandhealth.com/content/1/1/14.
% 
% \end{thebibliography}



\end{document}

